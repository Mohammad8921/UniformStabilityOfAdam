# Uniform Stability of Adam Algorithm and its Effect on Generalization Error of Neural Networks
## Abstract
* We connected the Lipschitz constant of a loss function to the generalization error of deep learning models trained by Adam and AdamW optimizers based on uniform stability theory.
* Using the generalziation bounds that we proved, we propose a novel loss function for training deep classification models to improve generalization performance and overcome the over-fitting issue.
* We assessed our theoretical results in age estimation.
* We used our new loss function in image and node classification in order to stabilize the output models and increase their accuarcy.
## Paper
* An original paper contains the theorems, proofs, and experiments on age estimation has been accepted for publication in Amirkabir Journal of Mathematics and Computing (AJMC);
* Published article: https://ajmc.aut.ac.ir/article_5213.html;
* PDF on arxiv: https://arxiv.org/abs/2303.16464.
