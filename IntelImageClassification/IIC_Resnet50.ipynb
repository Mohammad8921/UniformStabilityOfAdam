{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch import nn\n",
    "from torchvision import transforms, models, datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set: 14034\n",
      "Label frequencies of the training set: {'buildings': 2191, 'forest': 2271, 'glacier': 2404, 'mountain': 2512, 'sea': 2274, 'street': 2382}\n",
      "----------\n",
      "Size of the test set: 3000\n",
      "Label frequencies of the test set: {'buildings': 437, 'forest': 474, 'glacier': 553, 'mountain': 525, 'sea': 510, 'street': 501}\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIRECTORY = '../Datasets/Intel/'\n",
    "TRAINING_PATH = DATASET_DIRECTORY + 'seg_train/seg_train/'\n",
    "TEST_PATH = DATASET_DIRECTORY + 'seg_test/seg_test/'\n",
    "\n",
    "train_cat_counts = {}\n",
    "for cat in os.listdir(TRAINING_PATH):\n",
    "    counts = len(os.listdir(os.path.join(TRAINING_PATH, cat)))\n",
    "    train_cat_counts[cat] = counts\n",
    "\n",
    "test_cat_counts = {}\n",
    "for cat in os.listdir(TEST_PATH):\n",
    "    counts = len(os.listdir(os.path.join(TEST_PATH, cat)))    \n",
    "    test_cat_counts[cat] = counts\n",
    "\n",
    "print(\"Size of the training set:\", sum(train_cat_counts.values()))    \n",
    "print(\"Label frequencies of the training set:\", train_cat_counts)\n",
    "print(10*'-')\n",
    "print(\"Size of the test set:\", sum(test_cat_counts.values()))\n",
    "print(\"Label frequencies of the test set:\", test_cat_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting & Preprocessing & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "batch_size = 64\n",
    "# mean and std which for ResNet50\n",
    "mean = [0.485, 0.456, 0.406] \n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((150, 150)), # Resize all images \n",
    "                                       transforms.RandomResizedCrop(150),# Crop\n",
    "                                       transforms.RandomRotation(30), # Rotate \n",
    "                                       transforms.RandomHorizontalFlip(), # Flip\n",
    "                                       transforms.ToTensor(), # Convert\n",
    "                                       transforms.Normalize(torch.Tensor(mean), torch.Tensor(std)) # Normalize\n",
    "                                       ])\n",
    "\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize((150, 150)),\n",
    "                                     transforms.CenterCrop(150),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "                                     ])\n",
    "\n",
    "# Tmp torchvision datasets.Image folder to split into train and validation sets\n",
    "tmp_data = datasets.ImageFolder(TRAINING_PATH, transform=train_transforms)\n",
    "# len(tmp_data): 14034\n",
    "\n",
    "# Randomsplit tmp data based on length of dataset and set seed for reproducable split\n",
    "train_data, val_data = random_split(tmp_data, [10000, 4034], generator=torch.Generator().manual_seed(random_seed))\n",
    "# Test set with with test transforms \n",
    "test_data = datasets.ImageFolder(TEST_PATH, transform=test_transforms)\n",
    "\n",
    "\n",
    "# Set Pytorch dataloaders, batch_size, training set shuffle\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "def init(random_seed): \n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "def create_model():\n",
    "    random_seed = 42\n",
    "    init(random_seed)\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    # Freeze model params \n",
    "    for param in resnet.parameters():\n",
    "        param.required_grad = False\n",
    "    # Pull final fc layer feature dimensions\n",
    "    features = resnet.fc.in_features\n",
    "\n",
    "\n",
    "    # Build custom classifier which reduces Resnets 1000 out_features to 6\n",
    "    classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(features, 512)),\n",
    "                                            ('relu', nn.ReLU()),\n",
    "                                            ('drop', nn.Dropout(0.05)),\n",
    "                                            ('fc2', nn.Linear(512, 6)),\n",
    "                                            ]))\n",
    "    resnet.fc = classifier\n",
    "    # Pushing the model to cuda\n",
    "    resnet.to(device)\n",
    "    return resnet    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The train() & evalaute() functions: \n",
    "The evalute() function returns the avg model loss on the validation set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.nn import Softmax\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "def train(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_len = len(train_dataloader)\n",
    "    softmax_func = Softmax(dim=1)\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.5f}\".format(100 * (step / float(total_len)))\n",
    "        lossp = \"{0:.5f}\".format(total_loss/step)\n",
    "        filledLength = int(100 * step // total_len)\n",
    "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total_len} |{bar}| {percent}% complete, loss={lossp}', end='')\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        model.zero_grad()\n",
    "        preds = model(imgs)\n",
    "        preds = softmax_func(preds) \n",
    "        loss = loss_fn(preds.double(), labels.double())\n",
    "        total_loss += float(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = total_loss / total_len\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, loss_fn):\n",
    "    val_loss = 0\n",
    "    softmax_func = Softmax(dim=1)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            preds = model(imgs)\n",
    "            preds = softmax_func(preds)\n",
    "            loss = loss_fn(preds.double(), labels.double())\n",
    "            val_loss += loss.item()\n",
    "        return  val_loss / len(val_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\ell_{CE}(\\mathrm{\\hat{y}}, \\mathrm{y}) = -\\sum_{c=1}^{C} y_c\\log(\\hat{y}_c),\\,\\, \\ell_{RJM}(\\mathrm{\\hat{y}}, \\mathrm{y}) = \\sum_{c=1}^{C} y_c(1-\\sqrt{\\hat{y}_c}). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(y_hat, y):\n",
    "    return torch.sum(-1*torch.log(y_hat[range(y.size()[0]), y.long()]) / y.size()[0])\n",
    "\n",
    "def RJM(y_hat, y):\n",
    "    return torch.sum(1 - torch.sqrt(y_hat[range(y.size()[0]), y.long()])) / y.size()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimzier: Adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.51958\n",
      "\n",
      "Training Loss: 0.52112\n",
      "Val Loss: 0.36628\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.37112\n",
      "\n",
      "Training Loss: 0.37383\n",
      "Val Loss: 0.34848\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.35193\n",
      "\n",
      "Training Loss: 0.35617\n",
      "Val Loss: 0.40140\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.32811\n",
      "\n",
      "Training Loss: 0.33007\n",
      "Val Loss: 0.34848\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.30757\n",
      "\n",
      "Training Loss: 0.31103\n",
      "Val Loss: 0.37394\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.29766\n",
      "\n",
      "Training Loss: 0.30426\n",
      "Val Loss: 0.36157\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.28340\n",
      "\n",
      "Training Loss: 0.28409\n",
      "Val Loss: 0.37849\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.27344\n",
      "\n",
      "Training Loss: 0.27494\n",
      "Val Loss: 0.38213\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.25171\n",
      "\n",
      "Training Loss: 0.25354\n",
      "Val Loss: 0.38323\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.25578\n",
      "\n",
      "Training Loss: 0.25663\n",
      "Val Loss: 0.35675\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.20594\n",
      "\n",
      "Training Loss: 0.20766\n",
      "Val Loss: 0.30871\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.18682\n",
      "\n",
      "Training Loss: 0.18693\n",
      "Val Loss: 0.30289\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.17190\n",
      "\n",
      "Training Loss: 0.17251\n",
      "Val Loss: 0.31792\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.16617\n",
      "\n",
      "Training Loss: 0.17094\n",
      "Val Loss: 0.32588\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.15684\n",
      "\n",
      "Training Loss: 0.15913\n",
      "Val Loss: 0.32859\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.15512\n",
      "\n",
      "Training Loss: 0.15724\n",
      "Val Loss: 0.32875\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.15119\n",
      "\n",
      "Training Loss: 0.15359\n",
      "Val Loss: 0.31543\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.14667\n",
      "\n",
      "Training Loss: 0.14899\n",
      "Val Loss: 0.31369\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.13471\n",
      "\n",
      "Training Loss: 0.13529\n",
      "Val Loss: 0.31385\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.13959\n",
      "\n",
      "Training Loss: 0.14016\n",
      "Val Loss: 0.32947\n"
     ]
    }
   ],
   "source": [
    "resnet_adam_ce = create_model()\n",
    "history_resnet_adam_ce = []\n",
    "optimizer = Adam(resnet_adam_ce.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.2)\n",
    "loss_fn = CE\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=resnet_adam_ce, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=resnet_adam_ce, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_resnet_adam_ce.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_adam_ce.state_dict(), 'checkpoints/resnet_adam_ce.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RJM loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.17035\n",
      "\n",
      "Training Loss: 0.17109\n",
      "Val Loss: 0.12418\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.12047\n",
      "\n",
      "Training Loss: 0.12119\n",
      "Val Loss: 0.11796\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.11635\n",
      "\n",
      "Training Loss: 0.11737\n",
      "Val Loss: 0.11145\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.10658\n",
      "\n",
      "Training Loss: 0.10695\n",
      "Val Loss: 0.10335\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.10089\n",
      "\n",
      "Training Loss: 0.10223\n",
      "Val Loss: 0.12181\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.10088\n",
      "\n",
      "Training Loss: 0.10283\n",
      "Val Loss: 0.10404\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.09590\n",
      "\n",
      "Training Loss: 0.09611\n",
      "Val Loss: 0.11409\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.09475\n",
      "\n",
      "Training Loss: 0.09511\n",
      "Val Loss: 0.11513\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.08946\n",
      "\n",
      "Training Loss: 0.09009\n",
      "Val Loss: 0.10393\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.09048\n",
      "\n",
      "Training Loss: 0.09181\n",
      "Val Loss: 0.10940\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.07672\n",
      "\n",
      "Training Loss: 0.07765\n",
      "Val Loss: 0.08952\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.07149\n",
      "\n",
      "Training Loss: 0.07150\n",
      "Val Loss: 0.08997\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06734\n",
      "\n",
      "Training Loss: 0.06746\n",
      "Val Loss: 0.09048\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06479\n",
      "\n",
      "Training Loss: 0.06552\n",
      "Val Loss: 0.08746\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06218\n",
      "\n",
      "Training Loss: 0.06269\n",
      "Val Loss: 0.08764\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06310\n",
      "\n",
      "Training Loss: 0.06362\n",
      "Val Loss: 0.08993\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.05938\n",
      "\n",
      "Training Loss: 0.06007\n",
      "Val Loss: 0.08696\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06062\n",
      "\n",
      "Training Loss: 0.06140\n",
      "Val Loss: 0.08598\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.05645\n",
      "\n",
      "Training Loss: 0.05669\n",
      "Val Loss: 0.08971\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.05852\n",
      "\n",
      "Training Loss: 0.05863\n",
      "Val Loss: 0.08374\n"
     ]
    }
   ],
   "source": [
    "resnet_adam_rjm = create_model()\n",
    "history_resnet_adam_rjm = []\n",
    "optimizer = Adam(resnet_adam_rjm.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.2)\n",
    "loss_fn = RJM\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=resnet_adam_rjm, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=resnet_adam_rjm, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_resnet_adam_rjm.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_adam_rjm.state_dict(), 'checkpoints/resnet_adam_rjm.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50: Optimzier = Adam, Loss = CE\n",
      "----------\n",
      "Accuracy: 0.9303\n",
      "Macro F1: 0.9316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "y_true_adam_ce = np.array([])\n",
    "y_pred_adam_ce = np.array([])\n",
    "resnet_adam_ce.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = resnet_adam_ce(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_adam_ce = np.concatenate((y_true_adam_ce, labels))\n",
    "        y_pred_adam_ce = np.concatenate((y_pred_adam_ce, preds_indices))\n",
    "    \n",
    "print('ResNet50: Optimzier = Adam, Loss = CE')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_adam_ce, y_pred_adam_ce)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_adam_ce, y_pred_adam_ce, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50: Optimzier = Adam, Loss = RJM\n",
      "----------\n",
      "Accuracy: 0.9333\n",
      "Macro F1: 0.9344\n"
     ]
    }
   ],
   "source": [
    "y_true_adam_rjm = np.array([])\n",
    "y_pred_adam_rjm = np.array([])\n",
    "resnet_adam_rjm.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = resnet_adam_rjm(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_adam_rjm = np.concatenate((y_true_adam_rjm, labels))\n",
    "        y_pred_adam_rjm = np.concatenate((y_pred_adam_rjm, preds_indices))\n",
    "    \n",
    "print('ResNet50: Optimzier = Adam, Loss = RJM')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_adam_rjm, y_pred_adam_rjm)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_adam_rjm, y_pred_adam_rjm, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5211236263324392, 0.3662788840660633),\n",
       " (0.3738337056340272, 0.34847557853925804),\n",
       " (0.3561661091429295, 0.4014042705021646),\n",
       " (0.3300709551630286, 0.34847921219710604),\n",
       " (0.3110317377231622, 0.37393639802587),\n",
       " (0.30426419212868333, 0.3615676990753051),\n",
       " (0.2840873839409673, 0.37849040857422317),\n",
       " (0.2749438934988312, 0.3821292815661561),\n",
       " (0.2535405663117322, 0.3832281326770191),\n",
       " (0.2566287950289117, 0.35674530480115507),\n",
       " (0.2076587384739474, 0.30871358199585364),\n",
       " (0.18693415855161793, 0.3028861485514029),\n",
       " (0.17251129265662526, 0.31791534975557095),\n",
       " (0.17094331536051044, 0.3258771827141669),\n",
       " (0.15913319602446072, 0.3285852458541301),\n",
       " (0.15723968090885623, 0.3287524144916472),\n",
       " (0.15358784511969228, 0.31542618946321743),\n",
       " (0.14899157869579233, 0.3136909447593698),\n",
       " (0.13528603577670514, 0.3138545838512712),\n",
       " (0.14016297370950762, 0.3294708106245238)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_resnet_adam_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1710909175229467, 0.1241820521825257),\n",
       " (0.12119477126037126, 0.1179565539324267),\n",
       " (0.11737331433576148, 0.11144754334875963),\n",
       " (0.10695210480865146, 0.10335126070817457),\n",
       " (0.10222649812319123, 0.12181143858622763),\n",
       " (0.10283162556468133, 0.10403545881925864),\n",
       " (0.0961085461179765, 0.11408896312014379),\n",
       " (0.09511420006330132, 0.11512799966423011),\n",
       " (0.09009385966730193, 0.10393370109421442),\n",
       " (0.09180569817967296, 0.10939756850627085),\n",
       " (0.0776474704193143, 0.08951829057188145),\n",
       " (0.07149813548880722, 0.08997332833752728),\n",
       " (0.06746424187664365, 0.09047830009891578),\n",
       " (0.06551926781118288, 0.08745963771106847),\n",
       " (0.06268502617540031, 0.08764346090863134),\n",
       " (0.06361823495819843, 0.08992950103637859),\n",
       " (0.06006716849491907, 0.08695714598403825),\n",
       " (0.06140084702460135, 0.0859764061338285),\n",
       " (0.05668552570250547, 0.08971488299421546),\n",
       " (0.05862545204495123, 0.08373929366282151)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_resnet_adam_rjm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer: AdamW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.51902\n",
      "\n",
      "Training Loss: 0.52119\n",
      "Val Loss: 0.36622\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.37341\n",
      "\n",
      "Training Loss: 0.37638\n",
      "Val Loss: 0.35029\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.34797\n",
      "\n",
      "Training Loss: 0.35178\n",
      "Val Loss: 0.40574\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.33230\n",
      "\n",
      "Training Loss: 0.33477\n",
      "Val Loss: 0.34854\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.31152\n",
      "\n",
      "Training Loss: 0.31513\n",
      "Val Loss: 0.35111\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.30338\n",
      "\n",
      "Training Loss: 0.30980\n",
      "Val Loss: 0.34941\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.29103\n",
      "\n",
      "Training Loss: 0.29205\n",
      "Val Loss: 0.35484\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.27695\n",
      "\n",
      "Training Loss: 0.27839\n",
      "Val Loss: 0.37342\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.26909\n",
      "\n",
      "Training Loss: 0.27153\n",
      "Val Loss: 0.36658\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.26515\n",
      "\n",
      "Training Loss: 0.26643\n",
      "Val Loss: 0.36372\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.21155\n",
      "\n",
      "Training Loss: 0.21336\n",
      "Val Loss: 0.29629\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.19532\n",
      "\n",
      "Training Loss: 0.19546\n",
      "Val Loss: 0.30377\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.17924\n",
      "\n",
      "Training Loss: 0.18020\n",
      "Val Loss: 0.31206\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.17075\n",
      "\n",
      "Training Loss: 0.17484\n",
      "Val Loss: 0.30989\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.16084\n",
      "\n",
      "Training Loss: 0.16223\n",
      "Val Loss: 0.31468\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.15853\n",
      "\n",
      "Training Loss: 0.16137\n",
      "Val Loss: 0.32031\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.15218\n",
      "\n",
      "Training Loss: 0.15536\n",
      "Val Loss: 0.29951\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.15380\n",
      "\n",
      "Training Loss: 0.15634\n",
      "Val Loss: 0.30768\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.13882\n",
      "\n",
      "Training Loss: 0.14035\n",
      "Val Loss: 0.30950\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.14216\n",
      "\n",
      "Training Loss: 0.14278\n",
      "Val Loss: 0.31496\n"
     ]
    }
   ],
   "source": [
    "resnet_adamw_ce = create_model()\n",
    "history_resnet_adamw_ce = []\n",
    "optimizer = AdamW(resnet_adamw_ce.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.2)\n",
    "loss_fn = CE\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=resnet_adamw_ce, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=resnet_adamw_ce, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_resnet_adamw_ce.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_adamw_ce.state_dict(), './checkpoints/resnet_adamw_ce.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RJM loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.17024\n",
      "\n",
      "Training Loss: 0.17100\n",
      "Val Loss: 0.12623\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.12112\n",
      "\n",
      "Training Loss: 0.12219\n",
      "Val Loss: 0.10990\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.11454\n",
      "\n",
      "Training Loss: 0.11572\n",
      "Val Loss: 0.11382\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.10851\n",
      "\n",
      "Training Loss: 0.10944\n",
      "Val Loss: 0.11014\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.10553\n",
      "\n",
      "Training Loss: 0.10653\n",
      "Val Loss: 0.12236\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.10107\n",
      "\n",
      "Training Loss: 0.10295\n",
      "Val Loss: 0.10674\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.09677\n",
      "\n",
      "Training Loss: 0.09724\n",
      "Val Loss: 0.11481\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.09659\n",
      "\n",
      "Training Loss: 0.09689\n",
      "Val Loss: 0.11789\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.09421\n",
      "\n",
      "Training Loss: 0.09474\n",
      "Val Loss: 0.10734\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.09336\n",
      "\n",
      "Training Loss: 0.09430\n",
      "Val Loss: 0.12005\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.07996\n",
      "\n",
      "Training Loss: 0.08104\n",
      "Val Loss: 0.09235\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.07331\n",
      "\n",
      "Training Loss: 0.07336\n",
      "Val Loss: 0.08817\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06823\n",
      "\n",
      "Training Loss: 0.06842\n",
      "Val Loss: 0.09602\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06589\n",
      "\n",
      "Training Loss: 0.06673\n",
      "Val Loss: 0.08768\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06167\n",
      "\n",
      "Training Loss: 0.06250\n",
      "Val Loss: 0.08690\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06361\n",
      "\n",
      "Training Loss: 0.06466\n",
      "Val Loss: 0.08995\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.05906\n",
      "\n",
      "Training Loss: 0.05979\n",
      "Val Loss: 0.08609\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.06151\n",
      "\n",
      "Training Loss: 0.06231\n",
      "Val Loss: 0.08853\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.05498\n",
      "\n",
      "Training Loss: 0.05517\n",
      "Val Loss: 0.08957\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.05803\n",
      "\n",
      "Training Loss: 0.05810\n",
      "Val Loss: 0.08352\n"
     ]
    }
   ],
   "source": [
    "resnet_adamw_rjm = create_model()\n",
    "history_resnet_adamw_rjm = []\n",
    "optimizer = AdamW(resnet_adamw_rjm.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.2)\n",
    "loss_fn = RJM\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=resnet_adamw_rjm, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=resnet_adamw_rjm, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_resnet_adamw_rjm.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_adamw_rjm.state_dict(), './checkpoints/resnet_adamw_rjm.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50: Optimzier = AdamW, Loss = CE\n",
      "----------\n",
      "Accuracy: 0.9240\n",
      "Macro F1: 0.9250\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "y_true_adamw_ce = np.array([])\n",
    "y_pred_adamw_ce = np.array([])\n",
    "resnet_adamw_ce.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = resnet_adamw_ce(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_adamw_ce = np.concatenate((y_true_adamw_ce, labels))\n",
    "        y_pred_adamw_ce = np.concatenate((y_pred_adamw_ce, preds_indices))\n",
    "    \n",
    "print('ResNet50: Optimzier = AdamW, Loss = CE')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_adamw_ce, y_pred_adamw_ce)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_adamw_ce, y_pred_adamw_ce, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50: Optimzier = AdamW, Loss = RJM\n",
      "----------\n",
      "Accuracy: 0.9327\n",
      "Macro F1: 0.9338\n"
     ]
    }
   ],
   "source": [
    "y_true_adamw_rjm = np.array([])\n",
    "y_pred_adamw_rjm = np.array([])\n",
    "resnet_adamw_rjm.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = resnet_adamw_rjm(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_adamw_rjm = np.concatenate((y_true_adamw_rjm, labels))\n",
    "        y_pred_adamw_rjm = np.concatenate((y_pred_adamw_rjm, preds_indices))\n",
    "    \n",
    "print('ResNet50: Optimzier = AdamW, Loss = RJM')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_adamw_rjm, y_pred_adamw_rjm)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_adamw_rjm, y_pred_adamw_rjm, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5211869197761237, 0.3662214832224571),\n",
       " (0.37638492305927757, 0.35029315083552093),\n",
       " (0.35177524966134227, 0.4057437941621591),\n",
       " (0.3347677654928292, 0.3485434510306495),\n",
       " (0.3151344466616101, 0.3511142694684835),\n",
       " (0.30980044429886844, 0.3494145638771621),\n",
       " (0.292052720914867, 0.3548440974087757),\n",
       " (0.27839101560643914, 0.3734225654620497),\n",
       " (0.271529129905734, 0.36657615121041026),\n",
       " (0.2664250858989775, 0.36371731570640004),\n",
       " (0.21335830179964949, 0.2962864963447788),\n",
       " (0.19545648789146963, 0.30376670435865705),\n",
       " (0.1802044813985988, 0.3120615026225489),\n",
       " (0.174840092438375, 0.30989352864124614),\n",
       " (0.16222698908425598, 0.31467837200729054),\n",
       " (0.16137420706240307, 0.32031461923311616),\n",
       " (0.155363040968585, 0.2995059490467846),\n",
       " (0.15633707315679796, 0.30768371706274195),\n",
       " (0.14034787741642693, 0.30949955248220246),\n",
       " (0.14277555606997505, 0.3149612655513181)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_resnet_adamw_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1709992818184276, 0.1262312866976228),\n",
       " (0.12218630932306652, 0.10989512855088995),\n",
       " (0.11572456102301705, 0.11382152341737252),\n",
       " (0.10944051819728895, 0.11013725477811928),\n",
       " (0.10652974558401317, 0.12236079714127424),\n",
       " (0.10294787696165203, 0.10673688507216358),\n",
       " (0.09724366576050189, 0.11481460440476159),\n",
       " (0.09688954996342249, 0.11789443674625173),\n",
       " (0.09473631664699365, 0.10734031896739087),\n",
       " (0.09429680993091291, 0.12005224361164359),\n",
       " (0.08104422484290903, 0.0923537567588797),\n",
       " (0.07335685441677582, 0.08817151918668342),\n",
       " (0.06841700600245851, 0.09601770695038743),\n",
       " (0.06672805331099702, 0.0876779710650151),\n",
       " (0.06250444439937522, 0.08689891580334023),\n",
       " (0.06465917335596445, 0.08994873000682596),\n",
       " (0.059789863130357536, 0.08609395633328665),\n",
       " (0.06230710119849958, 0.0885274862162387),\n",
       " (0.05516688605892541, 0.0895703604390005),\n",
       " (0.05809657829438773, 0.08351975861865313)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_resnet_adamw_rjm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer: NovoGrad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.75857\n",
      "\n",
      "Training Loss: 1.76961\n",
      "Val Loss: 1.72659\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.67372\n",
      "\n",
      "Training Loss: 1.68438\n",
      "Val Loss: 1.63673\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.58073\n",
      "\n",
      "Training Loss: 1.59077\n",
      "Val Loss: 1.53326\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.46942\n",
      "\n",
      "Training Loss: 1.47815\n",
      "Val Loss: 1.41173\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.35215\n",
      "\n",
      "Training Loss: 1.36057\n",
      "Val Loss: 1.29687\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.24171\n",
      "\n",
      "Training Loss: 1.25013\n",
      "Val Loss: 1.18727\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.14539\n",
      "\n",
      "Training Loss: 1.15255\n",
      "Val Loss: 1.09849\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.06194\n",
      "\n",
      "Training Loss: 1.06830\n",
      "Val Loss: 1.02098\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.99878\n",
      "\n",
      "Training Loss: 1.00465\n",
      "Val Loss: 0.96227\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.95025\n",
      "\n",
      "Training Loss: 0.95638\n",
      "Val Loss: 0.91032\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.91924\n",
      "\n",
      "Training Loss: 0.92552\n",
      "Val Loss: 0.90377\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.91129\n",
      "\n",
      "Training Loss: 0.91647\n",
      "Val Loss: 0.89781\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.90513\n",
      "\n",
      "Training Loss: 0.91073\n",
      "Val Loss: 0.88764\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.89955\n",
      "\n",
      "Training Loss: 0.90621\n",
      "Val Loss: 0.87995\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.89158\n",
      "\n",
      "Training Loss: 0.89727\n",
      "Val Loss: 0.87312\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.88631\n",
      "\n",
      "Training Loss: 0.89470\n",
      "Val Loss: 0.85614\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.87856\n",
      "\n",
      "Training Loss: 0.88516\n",
      "Val Loss: 0.84849\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.87282\n",
      "\n",
      "Training Loss: 0.87924\n",
      "Val Loss: 0.85684\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.86632\n",
      "\n",
      "Training Loss: 0.87201\n",
      "Val Loss: 0.85369\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.86487\n",
      "\n",
      "Training Loss: 0.86972\n",
      "Val Loss: 0.84415\n"
     ]
    }
   ],
   "source": [
    "from torch_optimizer import NovoGrad\n",
    "resnet_novograd_ce = create_model()\n",
    "history_resnet_novograd_ce = []\n",
    "optimizer = NovoGrad(resnet_novograd_ce.parameters(), lr=2e-5, weight_decay=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.2)\n",
    "loss_fn = CE\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=resnet_novograd_ce, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=resnet_novograd_ce, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_resnet_novograd_ce.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_novograd_ce.state_dict(), './checkpoints/resnet_novograd_ce.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RJM loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.58230\n",
      "\n",
      "Training Loss: 0.58599\n",
      "Val Loss: 0.57761\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.56410\n",
      "\n",
      "Training Loss: 0.56770\n",
      "Val Loss: 0.55679\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.54057\n",
      "\n",
      "Training Loss: 0.54404\n",
      "Val Loss: 0.52746\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.50732\n",
      "\n",
      "Training Loss: 0.51036\n",
      "Val Loss: 0.49058\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.47341\n",
      "\n",
      "Training Loss: 0.47627\n",
      "Val Loss: 0.45965\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.44334\n",
      "\n",
      "Training Loss: 0.44631\n",
      "Val Loss: 0.42910\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.41646\n",
      "\n",
      "Training Loss: 0.41922\n",
      "Val Loss: 0.40248\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.39209\n",
      "\n",
      "Training Loss: 0.39435\n",
      "Val Loss: 0.38009\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.37328\n",
      "\n",
      "Training Loss: 0.37564\n",
      "Val Loss: 0.36096\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.35904\n",
      "\n",
      "Training Loss: 0.36146\n",
      "Val Loss: 0.34745\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.34979\n",
      "\n",
      "Training Loss: 0.35211\n",
      "Val Loss: 0.34515\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.34684\n",
      "\n",
      "Training Loss: 0.34889\n",
      "Val Loss: 0.34376\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.34519\n",
      "\n",
      "Training Loss: 0.34735\n",
      "Val Loss: 0.34163\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.34325\n",
      "\n",
      "Training Loss: 0.34571\n",
      "Val Loss: 0.33862\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.34114\n",
      "\n",
      "Training Loss: 0.34305\n",
      "Val Loss: 0.33747\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.33875\n",
      "\n",
      "Training Loss: 0.34189\n",
      "Val Loss: 0.32935\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.33694\n",
      "\n",
      "Training Loss: 0.33954\n",
      "Val Loss: 0.32642\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.33509\n",
      "\n",
      "Training Loss: 0.33748\n",
      "Val Loss: 0.33259\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.33338\n",
      "\n",
      "Training Loss: 0.33565\n",
      "Val Loss: 0.32837\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.33227\n",
      "\n",
      "Training Loss: 0.33423\n",
      "Val Loss: 0.32838\n"
     ]
    }
   ],
   "source": [
    "resnet_novograd_rjm = create_model()\n",
    "history_resnet_novograd_rjm = []\n",
    "optimizer = NovoGrad(resnet_novograd_rjm.parameters(), lr=2e-5, weight_decay=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.2)\n",
    "loss_fn = RJM\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=resnet_novograd_rjm, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=resnet_novograd_rjm, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_resnet_novograd_rjm.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet_novograd_rjm.state_dict(), './checkpoints/resnet_novograd_rjm.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50: Optimzier = NovoGrad, Loss = CE\n",
      "----------\n",
      "Accuracy: 0.9000\n",
      "Macro F1: 0.9017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "y_true_novograd_ce = np.array([])\n",
    "y_pred_novograd_ce = np.array([])\n",
    "resnet_novograd_ce.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = resnet_novograd_ce(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_novograd_ce = np.concatenate((y_true_novograd_ce, labels))\n",
    "        y_pred_novograd_ce = np.concatenate((y_pred_novograd_ce, preds_indices))\n",
    "    \n",
    "print('ResNet50: Optimzier = NovoGrad, Loss = CE')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_novograd_ce, y_pred_novograd_ce)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_novograd_ce, y_pred_novograd_ce, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50: Optimzier = NovoGrad, Loss = RJM\n",
      "----------\n",
      "Accuracy: 0.8613\n",
      "Macro F1: 0.8628\n"
     ]
    }
   ],
   "source": [
    "y_true_novograd_rjm = np.array([])\n",
    "y_pred_novograd_rjm = np.array([])\n",
    "resnet_novograd_rjm.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = resnet_novograd_rjm(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_novograd_rjm = np.concatenate((y_true_novograd_rjm, labels))\n",
    "        y_pred_novograd_rjm = np.concatenate((y_pred_novograd_rjm, preds_indices))\n",
    "    \n",
    "print('ResNet50: Optimzier = NovoGrad, Loss = RJM')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_novograd_rjm, y_pred_novograd_rjm)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_novograd_rjm, y_pred_novograd_rjm, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.7696074359300304, 1.726591405714355),\n",
       " (1.684379395772915, 1.6367316107849061),\n",
       " (1.5907694074404792, 1.533257928219406),\n",
       " (1.4781478356833422, 1.4117321305508121),\n",
       " (1.360569136828987, 1.2968722753024338),\n",
       " (1.2501271722670664, 1.18726661701816),\n",
       " (1.1525533763915345, 1.0984912266225924),\n",
       " (1.068300479561597, 1.020982341542207),\n",
       " (1.0046463363896139, 0.9622732391073091),\n",
       " (0.9563823065469463, 0.9103249969695046),\n",
       " (0.9255152381911919, 0.9037718805141852),\n",
       " (0.9164737442737289, 0.897812675911224),\n",
       " (0.9107325062079915, 0.8876433375518588),\n",
       " (0.9062128241900171, 0.8799535433505083),\n",
       " (0.8972670967855446, 0.8731199655559423),\n",
       " (0.8946993114058152, 0.8561358873947457),\n",
       " (0.885156897096847, 0.8484871495052847),\n",
       " (0.879242255836833, 0.8568448588709593),\n",
       " (0.872013505382355, 0.8536890657165954),\n",
       " (0.8697220123423104, 0.844154556461869)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_resnet_novograd_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5859933427719729, 0.5776148333454614),\n",
       " (0.5677035854923087, 0.5567878678087081),\n",
       " (0.5440380473387673, 0.527462957492915),\n",
       " (0.510355845195563, 0.4905752614488739),\n",
       " (0.4762738775749818, 0.45964539859941295),\n",
       " (0.44631414922084367, 0.4290971843377364),\n",
       " (0.41921969057332586, 0.4024792419603608),\n",
       " (0.3943487968522131, 0.3800920659241325),\n",
       " (0.3756393402137429, 0.36096390840167236),\n",
       " (0.361460909539164, 0.34744530580228616),\n",
       " (0.35211009271668914, 0.345150455258615),\n",
       " (0.348885664183551, 0.3437631526000867),\n",
       " (0.3473474513903913, 0.3416255913895775),\n",
       " (0.34571239384645736, 0.3386168456172915),\n",
       " (0.3430538903946337, 0.33747130707216205),\n",
       " (0.34189168894582084, 0.329347959510822),\n",
       " (0.3395442778039845, 0.3264184131821964),\n",
       " (0.33747545617756347, 0.33259250069513163),\n",
       " (0.33564703500869947, 0.32836778322758325),\n",
       " (0.33422996045346276, 0.328383730624638)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_resnet_novograd_rjm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
