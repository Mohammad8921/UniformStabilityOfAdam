{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "from torch import nn\n",
    "from torchvision import transforms, models, datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set: 14034\n",
      "Label frequencies of the training set: {'buildings': 2191, 'forest': 2271, 'glacier': 2404, 'mountain': 2512, 'sea': 2274, 'street': 2382}\n",
      "----------\n",
      "Size of the test set: 3000\n",
      "Label frequencies of the test set: {'buildings': 437, 'forest': 474, 'glacier': 553, 'mountain': 525, 'sea': 510, 'street': 501}\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIRECTORY = '../Datasets/Intel/'\n",
    "TRAINING_PATH = DATASET_DIRECTORY + 'seg_train/seg_train/'\n",
    "TEST_PATH = DATASET_DIRECTORY + 'seg_test/seg_test/'\n",
    "\n",
    "train_cat_counts = {}\n",
    "for cat in os.listdir(TRAINING_PATH):\n",
    "    counts = len(os.listdir(os.path.join(TRAINING_PATH, cat)))\n",
    "    train_cat_counts[cat] = counts\n",
    "\n",
    "test_cat_counts = {}\n",
    "for cat in os.listdir(TEST_PATH):\n",
    "    counts = len(os.listdir(os.path.join(TEST_PATH, cat)))    \n",
    "    test_cat_counts[cat] = counts\n",
    "\n",
    "print(\"Size of the training set:\", sum(train_cat_counts.values()))    \n",
    "print(\"Label frequencies of the training set:\", train_cat_counts)\n",
    "print(10*'-')\n",
    "print(\"Size of the test set:\", sum(test_cat_counts.values()))\n",
    "print(\"Label frequencies of the test set:\", test_cat_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting & Preprocessing & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "batch_size = 64\n",
    "# mean and std which for ResNet50\n",
    "mean = [0.485, 0.456, 0.406] \n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize((150, 150)), # Resize all images \n",
    "                                       transforms.RandomResizedCrop(150),# Crop\n",
    "                                       transforms.RandomRotation(30), # Rotate \n",
    "                                       transforms.RandomHorizontalFlip(), # Flip\n",
    "                                       transforms.ToTensor(), # Convert\n",
    "                                       transforms.Normalize(torch.Tensor(mean), torch.Tensor(std)) # Normalize\n",
    "                                       ])\n",
    "\n",
    "\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize((150, 150)),\n",
    "                                     transforms.CenterCrop(150),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "                                     ])\n",
    "\n",
    "# Tmp torchvision datasets.Image folder to split into train and validation sets\n",
    "tmp_data = datasets.ImageFolder(TRAINING_PATH, transform=train_transforms)\n",
    "# len(tmp_data): 14034\n",
    "\n",
    "# Randomsplit tmp data based on length of dataset and set seed for reproducable split\n",
    "train_data, val_data = random_split(tmp_data, [10000, 4034], generator=torch.Generator().manual_seed(random_seed))\n",
    "# Test set with with test transforms \n",
    "test_data = datasets.ImageFolder(TEST_PATH, transform=test_transforms)\n",
    "\n",
    "\n",
    "# Set Pytorch dataloaders, batch_size, training set shuffle\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "def init(random_seed): \n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "def create_model():\n",
    "    random_seed = 42\n",
    "    init(random_seed)\n",
    "    vgg = models.vgg16(pretrained=True)\n",
    "    # Freeze model params \n",
    "    for param in vgg.parameters():\n",
    "        param.requires_grad = False\n",
    "    vgg.classifier[6] = nn.Linear(in_features=4096, out_features=6)    \n",
    "    vgg.to(device)\n",
    "    return vgg    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The train() & evalaute() functions: \n",
    "The evalute() function returns the avg model loss on the validation set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.nn import Softmax\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "def train(model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_len = len(train_dataloader)\n",
    "    softmax_func = Softmax(dim=1)\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        step = i+1\n",
    "        percent = \"{0:.5f}\".format(100 * (step / float(total_len)))\n",
    "        lossp = \"{0:.5f}\".format(total_loss/step)\n",
    "        filledLength = int(100 * step // total_len)\n",
    "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
    "        print(f'\\rBatch {step}/{total_len} |{bar}| {percent}% complete, loss={lossp}', end='')\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        del batch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        model.zero_grad()\n",
    "        preds = model(imgs)\n",
    "        preds = softmax_func(preds) \n",
    "        loss = loss_fn(preds.double(), labels.double())\n",
    "        total_loss += float(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    avg_loss = total_loss / total_len\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "def evaluate(model, loss_fn):\n",
    "    val_loss = 0\n",
    "    softmax_func = Softmax(dim=1)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            preds = model(imgs)\n",
    "            preds = softmax_func(preds)\n",
    "            loss = loss_fn(preds.double(), labels.double())\n",
    "            val_loss += loss.item()\n",
    "        return  val_loss / len(val_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\ell_{CE}(\\mathrm{\\hat{y}}, \\mathrm{y}) = -\\sum_{c=1}^{C} y_c\\log(\\hat{y}_c),\\,\\, \\ell_{RJM}(\\mathrm{\\hat{y}}, \\mathrm{y}) = \\sum_{c=1}^{C} y_c(1-\\sqrt{\\hat{y}_c}). $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE(y_hat, y):\n",
    "    return torch.sum(-1*torch.log(y_hat[range(y.size()[0]), y.long()]) / y.size()[0])\n",
    "\n",
    "def RJM(y_hat, y):\n",
    "    return torch.sum(1 - torch.sqrt(y_hat[range(y.size()[0]), y.long()])) / y.size()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer: SGD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.73250\n",
      "\n",
      "Training Loss: 1.74232\n",
      "Val Loss: 1.55337\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.46992\n",
      "\n",
      "Training Loss: 1.47810\n",
      "Val Loss: 1.29958\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.21464\n",
      "\n",
      "Training Loss: 1.22149\n",
      "Val Loss: 1.05906\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=1.01528\n",
      "\n",
      "Training Loss: 1.02206\n",
      "Val Loss: 0.88318\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.87752\n",
      "\n",
      "Training Loss: 0.88406\n",
      "Val Loss: 0.75594\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.77547\n",
      "\n",
      "Training Loss: 0.78111\n",
      "Val Loss: 0.69469\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.72596\n",
      "\n",
      "Training Loss: 0.73022\n",
      "Val Loss: 0.64407\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.68152\n",
      "\n",
      "Training Loss: 0.68469\n",
      "Val Loss: 0.61090\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.66577\n",
      "\n",
      "Training Loss: 0.66957\n",
      "Val Loss: 0.58616\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.64062\n",
      "\n",
      "Training Loss: 0.64374\n",
      "Val Loss: 0.57838\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.64000\n",
      "\n",
      "Training Loss: 0.64638\n",
      "Val Loss: 0.57261\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.59754\n",
      "\n",
      "Training Loss: 0.60098\n",
      "Val Loss: 0.57288\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.62048\n",
      "\n",
      "Training Loss: 0.62754\n",
      "Val Loss: 0.55745\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.61653\n",
      "\n",
      "Training Loss: 0.61954\n",
      "Val Loss: 0.57081\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.60985\n",
      "\n",
      "Training Loss: 0.61284\n",
      "Val Loss: 0.56225\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.60832\n",
      "\n",
      "Training Loss: 0.61256\n",
      "Val Loss: 0.55243\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.60619\n",
      "\n",
      "Training Loss: 0.61122\n",
      "Val Loss: 0.57179\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.61389\n",
      "\n",
      "Training Loss: 0.61986\n",
      "Val Loss: 0.57557\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.60714\n",
      "\n",
      "Training Loss: 0.60925\n",
      "Val Loss: 0.53697\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.60907\n",
      "\n",
      "Training Loss: 0.61371\n",
      "Val Loss: 0.56776\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "vgg_sgd_ce = create_model()\n",
    "history_vgg_sgd_ce = []\n",
    "optimizer = SGD(vgg_sgd_ce.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,15], gamma=0.2)\n",
    "loss_fn = CE\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=vgg_sgd_ce, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=vgg_sgd_ce, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_vgg_sgd_ce.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg_sgd_ce.state_dict(), './checkpoints/vgg_sgd_ce.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RJM loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.56717\n",
      "\n",
      "Training Loss: 0.57048\n",
      "Val Loss: 0.53163\n",
      "\n",
      "Epoch 2 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.49889\n",
      "\n",
      "Training Loss: 0.50178\n",
      "Val Loss: 0.45738\n",
      "\n",
      "Epoch 3 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.42040\n",
      "\n",
      "Training Loss: 0.42273\n",
      "Val Loss: 0.37576\n",
      "\n",
      "Epoch 4 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.35078\n",
      "\n",
      "Training Loss: 0.35304\n",
      "Val Loss: 0.30936\n",
      "\n",
      "Epoch 5 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.29680\n",
      "\n",
      "Training Loss: 0.29900\n",
      "Val Loss: 0.25858\n",
      "\n",
      "Epoch 6 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.25775\n",
      "\n",
      "Training Loss: 0.25945\n",
      "Val Loss: 0.23127\n",
      "\n",
      "Epoch 7 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.23543\n",
      "\n",
      "Training Loss: 0.23689\n",
      "Val Loss: 0.20984\n",
      "\n",
      "Epoch 8 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.21853\n",
      "\n",
      "Training Loss: 0.21972\n",
      "Val Loss: 0.19941\n",
      "\n",
      "Epoch 9 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.20921\n",
      "\n",
      "Training Loss: 0.21052\n",
      "Val Loss: 0.18611\n",
      "\n",
      "Epoch 10 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.20036\n",
      "\n",
      "Training Loss: 0.20129\n",
      "Val Loss: 0.18512\n",
      "\n",
      "Epoch 11 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.19800\n",
      "\n",
      "Training Loss: 0.20018\n",
      "Val Loss: 0.18038\n",
      "\n",
      "Epoch 12 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.18612\n",
      "\n",
      "Training Loss: 0.18742\n",
      "Val Loss: 0.18134\n",
      "\n",
      "Epoch 13 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.19183\n",
      "\n",
      "Training Loss: 0.19451\n",
      "Val Loss: 0.17787\n",
      "\n",
      "Epoch 14 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.19135\n",
      "\n",
      "Training Loss: 0.19254\n",
      "Val Loss: 0.18032\n",
      "\n",
      "Epoch 15 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.19015\n",
      "\n",
      "Training Loss: 0.19127\n",
      "Val Loss: 0.17972\n",
      "\n",
      "Epoch 16 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.18867\n",
      "\n",
      "Training Loss: 0.19018\n",
      "Val Loss: 0.17485\n",
      "\n",
      "Epoch 17 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.18978\n",
      "\n",
      "Training Loss: 0.19163\n",
      "Val Loss: 0.18322\n",
      "\n",
      "Epoch 18 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.18850\n",
      "\n",
      "Training Loss: 0.19036\n",
      "Val Loss: 0.18262\n",
      "\n",
      "Epoch 19 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.18769\n",
      "\n",
      "Training Loss: 0.18829\n",
      "Val Loss: 0.16885\n",
      "\n",
      "Epoch 20 / 20:\n",
      "Batch 157/157 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00000% complete, loss=0.18691\n",
      "\n",
      "Training Loss: 0.18827\n",
      "Val Loss: 0.17995\n"
     ]
    }
   ],
   "source": [
    "vgg_sgd_rjm = create_model()\n",
    "history_vgg_sgd_rjm = []\n",
    "optimizer = SGD(vgg_sgd_rjm.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,15], gamma=0.2)\n",
    "loss_fn = RJM\n",
    "epochs = 20\n",
    "current = 1\n",
    "# for each epoch\n",
    "while current <= epochs:\n",
    "\n",
    "    print(f'\\nEpoch {current} / {epochs}:')\n",
    "\n",
    "    # train model\n",
    "    train_loss = train(model=vgg_sgd_rjm, loss_fn = loss_fn, optimizer=optimizer)\n",
    "\n",
    "    # evaluate model\n",
    "    val_loss = evaluate(model=vgg_sgd_rjm, loss_fn=loss_fn)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'\\n\\nTraining Loss: {train_loss:.5f}')\n",
    "    print(f'Val Loss: {val_loss:.5f}')\n",
    "\n",
    "    history_vgg_sgd_rjm.append((train_loss, val_loss))\n",
    "\n",
    "    current = current + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vgg_sgd_rjm.state_dict(), './checkpoints/vgg_sgd_rjm.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16: Optimzier = SGD, Loss = CE\n",
      "----------\n",
      "Accuracy: 0.7955\n",
      "Macro F1: 0.7959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "y_true_sgd_ce = np.array([])\n",
    "y_pred_sgd_ce = np.array([])\n",
    "vgg_sgd_ce.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = vgg_sgd_ce(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_sgd_ce = np.concatenate((y_true_sgd_ce, labels))\n",
    "        y_pred_sgd_ce = np.concatenate((y_pred_sgd_ce, preds_indices))\n",
    "    \n",
    "print('VGG16: Optimzier = SGD, Loss = CE')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_sgd_ce, y_pred_sgd_ce)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_sgd_ce, y_pred_sgd_ce, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16: Optimzier = SGD, Loss = RJM\n",
      "----------\n",
      "Accuracy: 0.7965\n",
      "Macro F1: 0.7979\n"
     ]
    }
   ],
   "source": [
    "y_true_sgd_rjm = np.array([])\n",
    "y_pred_sgd_rjm = np.array([])\n",
    "vgg_sgd_rjm.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        imgs, labels = batch[0].to(device), batch[1].to(device)\n",
    "        preds = vgg_sgd_rjm(imgs).detach().cpu().numpy()\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        preds_indices = preds.argmax(axis=1)\n",
    "        y_true_sgd_rjm = np.concatenate((y_true_sgd_rjm, labels))\n",
    "        y_pred_sgd_rjm = np.concatenate((y_pred_sgd_rjm, preds_indices))\n",
    "    \n",
    "print('VGG16: Optimzier = SGD, Loss = RJM')\n",
    "print(10*'-')    \n",
    "print('Accuracy: {0:0.4f}'.format(accuracy_score(y_true_sgd_rjm, y_pred_sgd_rjm)))\n",
    "print('Macro F1: {0:0.4f}'.format(f1_score(y_true_sgd_rjm, y_pred_sgd_rjm, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.7423240135226725, 1.5533659691856252),\n",
       " (1.4780956886157184, 1.2995807431223263),\n",
       " (1.2214885981900583, 1.0590605267544841),\n",
       " (1.0220575068178843, 0.8831785307282952),\n",
       " (0.884064616657325, 0.7559370820042073),\n",
       " (0.7811117078371027, 0.6946927015386313),\n",
       " (0.7302156766935419, 0.6440735018382869),\n",
       " (0.6846914576546775, 0.6108974151802413),\n",
       " (0.6695676376204002, 0.586160217179046),\n",
       " (0.643740174364163, 0.578380042515941),\n",
       " (0.646376258585805, 0.5726090452268723),\n",
       " (0.600983994311819, 0.5728806836768332),\n",
       " (0.6275388569137805, 0.557446680204475),\n",
       " (0.6195425294881943, 0.5708087187024208),\n",
       " (0.6128390177469346, 0.5622517098801383),\n",
       " (0.6125574280773124, 0.5524263972208142),\n",
       " (0.6112178223597535, 0.5717911694124375),\n",
       " (0.6198585868733744, 0.5755721611791537),\n",
       " (0.6092478541808485, 0.5369680360973882),\n",
       " (0.6137096162312751, 0.5677567470918513)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_vgg_sgd_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5704775954566864, 0.5316340580370936),\n",
       " (0.5017810324127187, 0.4573766043098394),\n",
       " (0.4227251482536649, 0.37575730192327406),\n",
       " (0.35303814075914297, 0.30936492929492004),\n",
       " (0.2990021932489004, 0.25858460376353537),\n",
       " (0.2594500796335141, 0.2312666115211531),\n",
       " (0.23688732374531754, 0.20983554466250665),\n",
       " (0.21971649039243407, 0.19940541755147845),\n",
       " (0.21052069261041553, 0.18610575934721577),\n",
       " (0.20129233437020352, 0.1851157993960144),\n",
       " (0.2001821538844043, 0.1803834613812447),\n",
       " (0.187417129825905, 0.1813401213039784),\n",
       " (0.19451413933755618, 0.17786807610848623),\n",
       " (0.1925444589187849, 0.1803185357622928),\n",
       " (0.19126707473123966, 0.17971547030658158),\n",
       " (0.19017836600713112, 0.1748474558278659),\n",
       " (0.19163240996089106, 0.18322362421806826),\n",
       " (0.19035898576771595, 0.18261689694455674),\n",
       " (0.18828590544896498, 0.16885118525259896),\n",
       " (0.18826672383058943, 0.17995293623837771)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_vgg_sgd_rjm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
